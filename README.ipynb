{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import load_data\n",
    "from sample_code_submission.model import model\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_files_per_town = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cellule suivante Ã  remplacer par une fonction : img, gt = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_data.load_images_in_path(\"./split_data/img_split_RGB_filtered\", limit_files_per_town)\n",
    "\n",
    "town_name_list = load_data.get_town_name_list(img)\n",
    "\n",
    "def dict_to_sorted_list(img_dict):\n",
    "    return sorted(img_dict.items(), key=lambda t: t[0])\n",
    "\n",
    "sorted_img = dict_to_sorted_list(img)\n",
    "\n",
    "gt = load_data.load_images_in_path(\"./split_data/gt_split_filtered\", limit_files_per_town)\n",
    "sorted_gt = dict_to_sorted_list(gt)\n",
    "\n",
    "def make_train_valid_sets(sorted_train, sorted_gt, town_name_list):\n",
    "    ratio = 0.8\n",
    "    train_img_list = []\n",
    "    train_gt_list = []\n",
    "    valid_img_list = []\n",
    "    valid_gt_list = []\n",
    "    for (n1,img),(n2,gt) in zip(sorted_train, sorted_gt):\n",
    "        if n1 != n2:\n",
    "            print(\"not sorted !\")\n",
    "        if random.random() < ratio:\n",
    "            train_img_list.append((n1,img))\n",
    "            train_gt_list.append((n2,gt))\n",
    "        else:\n",
    "            valid_img_list.append((n1,img))\n",
    "            valid_gt_list.append((n2,gt))\n",
    "    return {\"img\":train_img_list, \"gt\":train_gt_list}, {\"img\":valid_img_list,\"gt\":valid_gt_list}\n",
    "\n",
    "train, valid = make_train_valid_sets(sorted_img, sorted_gt, town_name_list)\n",
    "\n",
    "def img_sorted_list_to_numpy(sorted_img_list):\n",
    "    return np.asarray([(np.moveaxis(np.asarray(img).astype(float), -1, 0)/255.)[np.newaxis,:,:,:] for _,img in sorted_img_list])\n",
    "\n",
    "train_np = img_sorted_list_to_numpy(train[\"img\"])\n",
    "\n",
    "def gt_sorted_list_to_numpy(sorted_gt_img):\n",
    "    return np.asarray([np.where(np.asarray(gt).flatten() > 122, 1, 0) for _,gt in sorted_gt_img])\n",
    "\n",
    "gt_np = gt_sorted_list_to_numpy(train[\"gt\"])\n",
    "\n",
    "valid_img_np = img_sorted_list_to_numpy(valid[\"img\"])\n",
    "valid_gt_np = gt_sorted_list_to_numpy(valid[\"gt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1000000)\n",
      "(5, 1, 3, 1000, 1000)\n",
      "(14, 1, 3, 1000, 1000)\n",
      "(14, 1000000)\n"
     ]
    }
   ],
   "source": [
    "print(valid_gt_np.shape)\n",
    "print(valid_img_np.shape)\n",
    "print(train_np.shape)\n",
    "print(gt_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, image 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b7680bbc9faa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Cours/M2_AIC/Areal_project/sample_code_submission/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m.fit(train_np, gt_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = m.predict(valid_img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64711154 0.64690655 0.65070134 ... 0.64243585 0.6486125  0.64258927]\n",
      " [0.64753675 0.64642948 0.6481697  ... 0.64528537 0.65627539 0.64720386]\n",
      " [0.65467811 0.65100664 0.65654171 ... 0.64095926 0.6396054  0.64061582]\n",
      " [0.64984667 0.64760727 0.65094239 ... 0.64852899 0.64952713 0.64240193]\n",
      " [0.64756948 0.6456849  0.64796287 ... 0.64477777 0.65136892 0.64358878]]\n",
      "(5, 1000000)\n",
      "5 1000000\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "print(pred.shape)\n",
    "print(valid_img_np.shape[0], valid_img_np.shape[3] * valid_img_np.shape[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
