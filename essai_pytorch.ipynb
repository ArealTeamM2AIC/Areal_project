{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, img_w, img_h):\n",
    "        super(MyModel, self).__init__()\n",
    "        in_channels = 3 # RGB\n",
    "        self.out_channels = 10\n",
    "        kernel_conv = (5,5) # square kernel\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, self.out_channels, kernel_size=kernel_conv, padding=2)\n",
    "        self.rel = nn.ReLU()\n",
    "        \n",
    "        kernel_pool = (3,3)\n",
    "        self.pool = nn.MaxPool2d(kernel_pool, stride=1, padding=1)\n",
    "        \n",
    "        self.lin = nn.Linear(self.out_channels, 1)\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        out = self.conv(data)\n",
    "        out = self.rel(out)\n",
    "        out = self.pool(out)\n",
    "        out = out.squeeze(0).transpose(0,2)\n",
    "        out = out.contiguous().view(-1, self.out_channels)\n",
    "        out = self.lin(out)\n",
    "        return self.act(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_image(file):\n",
    "    return Image.open(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_in_path(path):\n",
    "    return {f: load_one_image(join(path, f)) for f in listdir(path) if isfile(join(path, f))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'image de train : 180\n"
     ]
    }
   ],
   "source": [
    "train_img = load_images_in_path(\"/home/samuel/Documents/Cours/M2_AIC/Projet/train/images\")\n",
    "print(\"Nombre d'image de train : %d\" % (len(train_img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_town_name_list(img_dict):\n",
    "    names = [f for f,img in img_dict.items()]\n",
    "    names = list(map(lambda n: re.search(\"[A-Za-z]+\", n).group(0), names))\n",
    "    return set(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kitsap', 'chicago', 'vienna', 'tyrol', 'austin'}\n"
     ]
    }
   ],
   "source": [
    "town_name_list = get_town_name_list(train_img)\n",
    "print(town_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_town_image = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_img_dict(img_dict, limit):\n",
    "    return {name: img for name, img in img_dict.items() if int(re.search(\"[0-9]+\", name).group(0)) <= limit}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "filtered_train_img = filter_img_dict(train_img, limit_town_image)\n",
    "print(len(filtered_train_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_sorted_list(img_dict):\n",
    "    return sorted(img_dict.items(), key=lambda t: t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('austin1.jpg', <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2500x2500 at 0x7FE3C39A2B70>)\n",
      "('austin1.jpg', <PIL.JpegImagePlugin.JpegImageFile image mode=L size=2500x2500 at 0x7FE3C390DB00>)\n",
      "('vienna3.jpg', <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2500x2500 at 0x7FE3C395CDA0>)\n",
      "('vienna3.jpg', <PIL.JpegImagePlugin.JpegImageFile image mode=L size=2500x2500 at 0x7FE3C38C1D30>)\n"
     ]
    }
   ],
   "source": [
    "sorted_train_img = dict_to_sorted_list(filtered_train_img)\n",
    "\n",
    "gt_img = load_images_in_path(\"/home/samuel/Documents/Cours/M2_AIC/Projet/train/gt\")\n",
    "filtered_gt_img = filter_img_dict(gt_img, limit_town_image)\n",
    "sorted_gt_img = dict_to_sorted_list(filtered_gt_img)\n",
    "\n",
    "print(sorted_train_img[0])\n",
    "print(sorted_gt_img[0])\n",
    "print(sorted_train_img[-1])\n",
    "print(sorted_gt_img[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_valid_sets(sorted_train, sorted_gt, town_name_list):\n",
    "    limit = 3\n",
    "    train_town_name_list = list(town_name_list)[0:limit]\n",
    "    train_img_list = []\n",
    "    train_gt_list = []\n",
    "    valid_img_list = []\n",
    "    valid_gt_list = []\n",
    "    for (n1,img),(n2,gt) in zip(sorted_train, sorted_gt):\n",
    "        if n1 != n2:\n",
    "            print(\"not sorted !\")\n",
    "        n1 = re.search(\"[A-Za-z]+\", n1).group(0)\n",
    "        if n1 in train_town_name_list:\n",
    "            train_img_list.append((n1,img))\n",
    "            train_gt_list.append((n2,gt))\n",
    "        else:\n",
    "            valid_img_list.append((n1,img))\n",
    "            valid_gt_list.append((n2,gt))\n",
    "    return {\"img\":train_img_list, \"gt\":train_gt_list}, {\"img\":valid_img_list,\"gt\":valid_gt_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = make_train_valid_sets(sorted_train_img, sorted_gt_img, town_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_sorted_list_to_numpy(sorted_img_list):\n",
    "    return [np.expand_dims(np.moveaxis(np.asarray(img), -1, 0), axis=0)/255. for _,img in sorted_img_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np = img_sorted_list_to_numpy(train[\"img\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2500, 2500)\n"
     ]
    }
   ],
   "source": [
    "print(train_np[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt_sorted_list_to_numpy(sorted_gt_img):\n",
    "    return [(np.asarray(gt).flatten().reshape(-1 ,1)/255.>0.5).astype(int) for _,gt in sorted_gt_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_np = gt_sorted_list_to_numpy(train[\"gt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6250000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(gt_np[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_img_np = img_sorted_list_to_numpy(valid[\"img\"])\n",
    "valid_gt_np = gt_sorted_list_to_numpy(valid[\"gt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(train_np))\n",
    "print(len(valid_img_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "img = load_one_image(\"austin1.jpg\")\n",
    "label = load_one_image(\"austin1_label.jpg\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "type(img)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "arr = np.asarray(img)\n",
    "label = np.asarray(label)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "print(arr.shape)\n",
    "print(label.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "w = arr.shape[0]\n",
    "h = arr.shape[1]\n",
    "c = arr.shape[2]\n",
    "arr = arr.reshape(1, c, w, h) \n",
    "label = label.flatten().reshape(-1 ,1)\n",
    "\n",
    "print(label.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "print(arr.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = list(zip(train_np, gt_np))\n",
    "random.shuffle(tmp)\n",
    "train_np, gt_np = zip(*tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss = 0.577511, accuracy = 0.885177\n",
      "Epoch 1, loss = 0.521113, accuracy = 0.885177\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7914a056ae73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nbEpoch = 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = MyModel(2500, 2500)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "optim = th.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in range(nbEpoch):\n",
    "    model.train()\n",
    "    sum_loss = 0\n",
    "    for img, gt in zip(train_np, gt_np):\n",
    "        optim.zero_grad()\n",
    "        out = model(th.FloatTensor(img))\n",
    "        loss = loss_fn(out, th.FloatTensor(gt))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        sum_loss += loss.item()\n",
    "    sum_loss /= len(train_np)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for img, gt in zip(valid_img_np, valid_gt_np):\n",
    "        y = model(th.FloatTensor(img))\n",
    "        tmp = (y > 0.5) == th.ByteTensor(gt)\n",
    "        total += tmp.size(0)\n",
    "        correct += tmp.sum().item()\n",
    "    print(\"Epoch %d, loss = %f, accuracy = %f\" % (i, sum_loss, correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
